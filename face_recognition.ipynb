{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac94733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy, datetime, pygame, keyboard\n",
    "import xlwings as xw\n",
    "# !pip install xlwings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xlwings\n",
    "#initializing workbook and worksheet\n",
    "workbook = xw.Book('attendance.xlsx')\n",
    "sheet_name = datetime.date.today().isoformat()\n",
    "print(sheet_name)\n",
    "try:\n",
    "    worksheet = workbook.sheets(sheet_name)\n",
    "except:\n",
    "    worksheet = workbook.sheets.add(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xlwings\n",
    "if worksheet.range('A1').value is None:\n",
    "    worksheet.range('A1').value = 'STUDENT'\n",
    "    worksheet.range('B1').value = 'DATE'\n",
    "    worksheet.range('C1').value = 'TIME'\n",
    "students = []\n",
    "rows = worksheet.range('A2:A' + str(worksheet.cells.last_cell.row)).value  # Read column A from row 2\n",
    "if rows:\n",
    "    students = [row for row in rows if row is not None]  # Filter out empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s= 2\n",
    "i = 0\n",
    "entered = False\n",
    "al_entered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fa62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the camera.\")\n",
    "    exit()\n",
    "\n",
    "for _ in range(10):  \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply sharpening kernel\n",
    "    kernel = np.array([[0, -1, 0], \n",
    "                       [-1, 5, -1], \n",
    "                       [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(frame_rgb, -1, kernel)\n",
    "\n",
    "    # Convert to grayscale and apply histogram equalization\n",
    "    gray = cv2.cvtColor(sharpened, cv2.COLOR_RGB2GRAY)\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Show results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(sharpened)\n",
    "    ax[0].set_title(\"Sharpened Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(equalized, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Histogram Equalized Image\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to grab frame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86509847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"[ droidcam.py ] - Initializing...\")\n",
    "\n",
    "    # Opening video stream of ip camera via its url\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Corrective actions printed in the even of failed connection.\n",
    "    if cap.isOpened() is not True:\n",
    "        print ('Not opened.')\n",
    "        print ('Please ensure the following:')\n",
    "        print ('1. DroidCam is not running in your browser.')\n",
    "        print ('2. The IP address given is correct.')\n",
    "\n",
    "    # Connection successful. Proceeding to display video stream.\n",
    "    while cap.isOpened() is True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Turning your frames into grayscale\n",
    "        # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        # cv2.imshow('gray',gray)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Path to your video file\n",
    "video_path = \"D:\\PROJECTS\\Roadmap\\OneCameraFinalVideo.mp4\"  # Replace with the actual path to your video file\n",
    "\n",
    "# Open the video capture (video from storage)\n",
    "cap = cv2.VideoCapture(\"http://192.168.0.70:4747/video\")\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"video opend\")\n",
    "frame_count=1\n",
    "frame_skip=20\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"End of video or failed to read the frame. Exiting...\")\n",
    "        break\n",
    "    \n",
    "    if frame_count < frame_skip:\n",
    "        frame_count += 1\n",
    "        continue\n",
    "    else:\n",
    "        frame_count=1\n",
    "    # Detect faces in the frame using RetinaFace\n",
    "    obj = RetinaFace.detect_faces(frame)\n",
    "\n",
    "    for key in obj.keys():\n",
    "        identity = obj[key]\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (facial_area[0], facial_area[1]), (facial_area[2], facial_area[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow(\"frame\",frame)  # Use cv2_imshow for Colab compatibility\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "        break\n",
    "    # To avoid freezing in Google Colab, there's no need to wait for 'q' here,\n",
    "    # but if you're running it on local machine, you can use cv2.waitKey(1) & 0xFF == ord('q') to quit\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadff6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res  = DeepFace.find(\"D:\\PROJECTS\\Roadmap\\yash.jpg\", db_path='./Database/', enforce_detection=False, model_name='VGG-Face')\n",
    "print(res)\n",
    "name = res[0]['identity'][0].split('\\\\')[0].split('/')[2]\n",
    "\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape = (480, 640, 3)  \n",
    "print(frame.shape[1::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182db29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Path to your video file\n",
    "video_path = \"OneCameraFinalVideo.mp4\"  # Replace with the actual path to your video file\n",
    "\n",
    "# Open the video capture (video from storage)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"End of video or failed to read the frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Detect faces in the frame using RetinaFace\n",
    "    obj = RetinaFace.detect_faces(frame)\n",
    "\n",
    "    for key in obj.keys():\n",
    "        identity = obj[key]\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (facial_area[0], facial_area[1]), (facial_area[2], facial_area[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow(\"frame\",frame)  # Use cv2_imshow for Colab compatibility\n",
    "\n",
    "    # To avoid freezing in Google Colab, there's no need to wait for 'q' here,\n",
    "    # but if you're running it on local machine, you can use cv2.waitKey(1) & 0xFF == ord('q') to quit\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# IP camera URL\n",
    "video_path = \"http://192.168.0.70:4747/video\"  # Your live stream link\n",
    "\n",
    "# Open the video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Video opened successfully.\")\n",
    "\n",
    "frame_skip = 10  # Reduce the number of skipped frames\n",
    "frame_count = 0\n",
    "prev_time = time.time()  # Track time for performance monitoring\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or failed to read the frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Process every `frame_skip` frame\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue\n",
    "    \n",
    "    # Measure time taken for frame processing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Detect faces using RetinaFace\n",
    "    obj = RetinaFace.detect_faces(frame)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for key in obj.keys():\n",
    "        identity = obj[key]\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "        cv2.rectangle(frame, (facial_area[0], facial_area[1]), (facial_area[2], facial_area[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    # Calculate FPS\n",
    "    end_time = time.time()\n",
    "    fps = 1 / (end_time - prev_time)\n",
    "    prev_time = end_time\n",
    "    print(f\"FPS: {fps:.2f}\")  # Print FPS to check performance\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e953d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from retinaface.pre_trained_models import get_model  # Import the correct function\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Load the pre-trained RetinaFace model (ResNet50 backbone)\n",
    "model = get_model(\"resnet50\")  \n",
    "model.eval()  # Set model to evaluation mode\n",
    "model.to(device)  # Move model to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d49ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "cv2.setUseOptimized(True)  # Enable OpenCV optimizations\n",
    "\n",
    "# Open video source\n",
    "cap = cv2.VideoCapture(0)  # Use webcam\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.49:4747/video\")  # Use mobile camera (DroidCam)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"‚úÖ Video opened successfully\")\n",
    "\n",
    "frame_skip = 10  # Skip frames for better performance\n",
    "frame_count = 0  # Frame counter\n",
    "\n",
    "# Check for GPU availability with PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")  # Force CPU usage\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(f\"Using device: {device}\")  # Check if GPU or CPU is being used\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üî¥ End of video. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames for efficiency\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))  # Resize for faster processing\n",
    "\n",
    "    # Detect faces\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Detect faces using RetinaFace\n",
    "    obj = RetinaFace.detect_faces(frame)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for key in obj.keys():\n",
    "        identity = obj[key]\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "        cv2.rectangle(frame, (facial_area[0], facial_area[1]), (facial_area[2], facial_area[3]), (0, 255, 0), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    # Calculate FPS\n",
    "    end_time = time.time()\n",
    "    fps = 1 / (end_time - prev_time)\n",
    "    prev_time = end_time\n",
    "    print(f\"FPS: {fps:.2f}\")  # Print FPS to check performance\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "cv2.setUseOptimized(True)\n",
    "\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.70:4747/video\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"‚úÖ Video opened successfully\")\n",
    "\n",
    "# Initialize RetinaFace with MobileNet and GPU usage (if available)\n",
    "\n",
    "frame_skip = 10 # Adjust as needed\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üî¥ End of video. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    obj = RetinaFace.detect_faces(frame_resized)  # Use the initialized detector\n",
    "\n",
    "    if obj:\n",
    "        for key in obj.keys():\n",
    "            identity = obj[key]\n",
    "            facial_area = identity[\"facial_area\"]\n",
    "            print(f\"Face detected at: {facial_area}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    fps = 1 / (end_time - start_time) if (end_time - start_time) > 0 else 0\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9731c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "  File \"C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_20400\\3572253753.py\", line 1, in <module>\n",
      "    import cv2\n",
      "ModuleNotFoundError: No module named 'cv2'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1136, in get_records\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "from retinaface import RetinaFace\n",
    "import numpy as np\n",
    "\n",
    "cv2.setUseOptimized(True)  # Enable OpenCV optimizations\n",
    "\n",
    "# Ensure CUDA is available\n",
    "assert torch.cuda.is_available(), \"‚ùå No GPU found! Make sure CUDA is installed and enabled.\"\n",
    "\n",
    "device = torch.device(\"cuda\")  # Force GPU usage\n",
    "print(f\"‚úÖ Running on {device} (GPU-Only Mode)\")\n",
    "\n",
    "# Open video source (0 = default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 10  # Skip frames to optimize performance\n",
    "frame_count = 0\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üî¥ End of video. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames to improve speed\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))  # Resize for faster processing\n",
    "\n",
    "    # Convert frame to PyTorch tensor and move it to GPU\n",
    "    frame_gpu = torch.tensor(frame_resized, device=\"cuda\").float()  # Move frame to GPU\n",
    "\n",
    "    # Detect faces using RetinaFace (forcing GPU execution)\n",
    "    start_time = time.time()\n",
    "    faces = RetinaFace.detect_faces(frame_gpu.cpu().numpy())  # Process and return to CPU\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    if isinstance(faces, dict):\n",
    "        for key in faces.keys():\n",
    "            identity = faces[key]\n",
    "            x1, y1, x2, y2 = identity[\"facial_area\"]\n",
    "            cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # FPS calculation\n",
    "    fps = 1 / (end_time - prev_time)\n",
    "    prev_time = end_time\n",
    "    print(f\"FPS: {fps:.2f}\")  # Print FPS for performance monitoring\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame_resized, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Face Detection (GPU-Only)\", frame_resized)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea8f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model file exists and is not empty.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"yolov8n-face.pt\"\n",
    "if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "    print(\"‚úÖ Model file exists and is not empty.\")\n",
    "else:\n",
    "    print(\"‚ùå Model file is missing or corrupt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59be87ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "  File \"C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_20400\\1147956241.py\", line 1, in <module>\n",
      "    import cv2\n",
      "ModuleNotFoundError: No module named 'cv2'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1136, in get_records\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "from retinaface import RetinaFace  # Corrected import\n",
    "import numpy as np\n",
    "\n",
    "cv2.setUseOptimized(True)\n",
    "\n",
    "assert torch.cuda.is_available(), \"‚ùå No GPU found!\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"‚úÖ Running on {device} (GPU-Only Mode)\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 2\n",
    "frame_count = 0\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üî¥ End of video. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    start_time = time.time()\n",
    "    faces = RetinaFace.detect_faces(frame_resized)  # Uses GPU if properly installed\n",
    "    end_time = time.time()\n",
    "\n",
    "    if isinstance(faces, dict):\n",
    "        for key in faces.keys():\n",
    "            identity = faces[key]\n",
    "            x1, y1, x2, y2 = identity[\"facial_area\"]\n",
    "            cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    fps = 1 / (end_time - prev_time)\n",
    "    prev_time = end_time\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "    cv2.putText(frame_resized, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Detection (GPU-Only)\", frame_resized)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f982e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "  File \"C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_20400\\2858965498.py\", line 1, in <module>\n",
      "    import cv2\n",
      "ModuleNotFoundError: No module named 'cv2'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1136, in get_records\n",
      "  File \"c:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "cv2.setUseOptimized(True)  # Enable OpenCV optimizations\n",
    "\n",
    "# Ensure GPU is available\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if not gpus:\n",
    "    print(\"‚ùå No GPU found! Make sure TensorFlow detects your GPU.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"‚úÖ Running on {gpus[0]} (GPU-Only Mode)\")\n",
    "\n",
    "# Open video source (0 = default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 10  # Skip frames to optimize performance\n",
    "frame_count = 0\n",
    "prev_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"üî¥ End of video. Exiting...\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames to improve speed\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))  # Resize for faster processing\n",
    "\n",
    "    # Convert frame to TensorFlow tensor and move it to GPU\n",
    "    frame_gpu = tf.convert_to_tensor(frame_resized, dtype=tf.float32)  # Move frame to GPU\n",
    "\n",
    "    # Detect faces using RetinaFace (forcing GPU execution)\n",
    "    start_time = time.time()\n",
    "    faces = RetinaFace.detect_faces(frame_gpu.numpy())  # Process frame\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    if isinstance(faces, dict):\n",
    "        for key in faces.keys():\n",
    "            identity = faces[key]\n",
    "            x1, y1, x2, y2 = identity[\"facial_area\"]\n",
    "            cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # FPS calculation\n",
    "    fps = 1 / (end_time - prev_time)\n",
    "    prev_time = end_time\n",
    "    print(f\"FPS: {fps:.2f}\")  # Print FPS for performance monitoring\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame_resized, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Face Detection (GPU-Only)\", frame_resized)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489b7d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\Ayush\\Downloads\\face_recog_attendance\\myenv\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
